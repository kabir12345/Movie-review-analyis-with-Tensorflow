{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOEFkIKi_VL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIqY_sEn_b0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the data set\n",
        "data=keras.datasets.imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv2ltx7r_ijH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab688adc-fc57-4609-8abf-1a7567577883"
      },
      "source": [
        "#loading the data\n",
        "(train_data,train_labels),(test_data,test_labels)=data.load_data(num_words=88000)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOLg9D-O_y0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e6800a92-2ad6-46a7-85e0-cdfd7067d8ac"
      },
      "source": [
        "#visualising data\n",
        "print(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75swBCH_5r9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "245574cd-f950-416e-a864-6162c1234cdd"
      },
      "source": [
        "#Collecting the word index for the dataset\n",
        "word_index=data.get_word_index()\n",
        "#creating a maaping for the words and defining our own tokens\n",
        "word_index={k:(v+3) for k,v  in word_index.items()}\n",
        "word_index[\"<PAD>\"]=0\n",
        "word_index[\"<START>\"]=1\n",
        "word_index[\"<UNK>\"]=2\n",
        "word_index[\"<UNUSED>\"]=3\n",
        "reverse_word_index=dict([(value,key)for(key,value) in word_index.items()])\n",
        "def decode_review(text):\n",
        "  return \" \".join([reverse_word_index.get(i,\"?\") for i in text])\n",
        "print(decode_review(test_data[0]))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "<START> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acsaZK8_AK7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing data to create even enteries for our imput layer in the neural network\n",
        "train_data=keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
        "test_data=keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkrvhpMAAfcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining our model and its layers\n",
        "model=keras.Sequential()\n",
        "#embedding layer has 88000 vocab and 16 dimensions to create its word vectors\n",
        "model.add(keras.layers.Embedding(88000,16))\n",
        "#flatening the 16 dimensional data into 1 dim \n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikq3uby1AmB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "#dividing the train data into validation and training data\n",
        "x_val=train_data[:10000]\n",
        "x_train=train_data[10000:]\n",
        "y_val=train_labels[:10000]\n",
        "y_train=train_labels[10000:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIImHtz4BGnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4dfe88b-2330-4e98-c035-be385f016eb7"
      },
      "source": [
        "fitModel=model.fit(x_train,y_train,epochs=40,batch_size=512,validation_data=(x_val,y_val),verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.6922 - accuracy: 0.5917 - val_loss: 0.6907 - val_accuracy: 0.6959\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.6877 - accuracy: 0.7132 - val_loss: 0.6840 - val_accuracy: 0.7143\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.6765 - accuracy: 0.7651 - val_loss: 0.6694 - val_accuracy: 0.7209\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6544 - accuracy: 0.7630 - val_loss: 0.6438 - val_accuracy: 0.7782\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6183 - accuracy: 0.8046 - val_loss: 0.6057 - val_accuracy: 0.7821\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.5704 - accuracy: 0.8222 - val_loss: 0.5608 - val_accuracy: 0.8074\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.5159 - accuracy: 0.8454 - val_loss: 0.5137 - val_accuracy: 0.8219\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.4607 - accuracy: 0.8639 - val_loss: 0.4696 - val_accuracy: 0.8348\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.4100 - accuracy: 0.8797 - val_loss: 0.4313 - val_accuracy: 0.8460\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.3654 - accuracy: 0.8918 - val_loss: 0.3988 - val_accuracy: 0.8575\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.3274 - accuracy: 0.9029 - val_loss: 0.3735 - val_accuracy: 0.8632\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.2947 - accuracy: 0.9124 - val_loss: 0.3530 - val_accuracy: 0.8681\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.2675 - accuracy: 0.9187 - val_loss: 0.3364 - val_accuracy: 0.8738\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.2435 - accuracy: 0.9265 - val_loss: 0.3231 - val_accuracy: 0.8759\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.2228 - accuracy: 0.9337 - val_loss: 0.3144 - val_accuracy: 0.8786\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.2042 - accuracy: 0.9405 - val_loss: 0.3038 - val_accuracy: 0.8813\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1878 - accuracy: 0.9450 - val_loss: 0.2974 - val_accuracy: 0.8833\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1733 - accuracy: 0.9509 - val_loss: 0.2919 - val_accuracy: 0.8844\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1596 - accuracy: 0.9555 - val_loss: 0.2869 - val_accuracy: 0.8855\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1477 - accuracy: 0.9606 - val_loss: 0.2837 - val_accuracy: 0.8862\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1365 - accuracy: 0.9657 - val_loss: 0.2807 - val_accuracy: 0.8866\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1265 - accuracy: 0.9686 - val_loss: 0.2786 - val_accuracy: 0.8882\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1172 - accuracy: 0.9724 - val_loss: 0.2776 - val_accuracy: 0.8882\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1089 - accuracy: 0.9755 - val_loss: 0.2766 - val_accuracy: 0.8880\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1012 - accuracy: 0.9773 - val_loss: 0.2757 - val_accuracy: 0.8886\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0943 - accuracy: 0.9802 - val_loss: 0.2766 - val_accuracy: 0.8886\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0882 - accuracy: 0.9813 - val_loss: 0.2760 - val_accuracy: 0.8894\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0818 - accuracy: 0.9835 - val_loss: 0.2767 - val_accuracy: 0.8894\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0762 - accuracy: 0.9860 - val_loss: 0.2777 - val_accuracy: 0.8899\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0715 - accuracy: 0.9865 - val_loss: 0.2790 - val_accuracy: 0.8893\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0665 - accuracy: 0.9884 - val_loss: 0.2812 - val_accuracy: 0.8891\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0622 - accuracy: 0.9888 - val_loss: 0.2823 - val_accuracy: 0.8894\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0584 - accuracy: 0.9900 - val_loss: 0.2842 - val_accuracy: 0.8888\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0544 - accuracy: 0.9913 - val_loss: 0.2858 - val_accuracy: 0.8889\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0512 - accuracy: 0.9920 - val_loss: 0.2882 - val_accuracy: 0.8884\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0480 - accuracy: 0.9928 - val_loss: 0.2921 - val_accuracy: 0.8876\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0449 - accuracy: 0.9931 - val_loss: 0.2923 - val_accuracy: 0.8879\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0422 - accuracy: 0.9939 - val_loss: 0.2962 - val_accuracy: 0.8877\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0396 - accuracy: 0.9945 - val_loss: 0.2996 - val_accuracy: 0.8868\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0374 - accuracy: 0.9945 - val_loss: 0.3008 - val_accuracy: 0.8865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKU8kx6pBIv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19958871-9139-4081-d63f-2fa6f46c261e"
      },
      "source": [
        "result=model.evaluate(test_data,test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXVKqQfuBYqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfc2be4b-ca87-4d66-f418-d170304d72f5"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3341594934463501, 0.8723199963569641]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSkDCuIQBcww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"text_pred.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}